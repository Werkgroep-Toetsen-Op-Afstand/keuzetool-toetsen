---
title: "Approach"
icon: /icons/tools.png
menuicon: /icons/tools-menu.png
date: 2020-07-31T11:05:44+02:00
expandable: true
instructions: false
weight: 3
---

Depending on whether **formative** or **summative** assessment is used, there are different steps to be taken in the approach. The number of students and the amount of available grading time also determine the possibility of including more or fewer questions that cannot be marked automatically.

## Formative assessment

### Preparation

Preferably use the same test system as for the summative test, so that students can get used to the environment.

In addition, it is recommended to design questions or didactic learning materials well before the start of the education. This is very time consuming. However, the use of student assistants can offer a solution here. See also [this interview](https://youtu.be/Z6Ie_ELBq40?t=1219) in which this is discussed.

### During

Taking a formative test need not be limited to a specific moment. Assignments can also be opened for a week or in preparation for a lecture or work group.

### After

To promote an optimal learning effect, it is relevant to give students access to the results and model answers after the formative test.

For the teacher, the results provide insight into where the knowledge gaps are. These insights can then be used during the current course to steer the teaching.

### Points of attention

* Whether or not formative tests are included in the assessment and the way in which they are taken into account can influence the efforts of students. This can play a role, especially with large groups. Consider a different reward system. Such as a [penalty scale](https://webcolleges.uva.nl/Mediasite/Play/2d74e9c589094bb0bc027cfbae672d6b1d), as also described in [@klinkenberg2016role].

> For a course whose subject matter was also tested at a later point in the programme, we converted a summative multiple-choice test into a formative test. This test is taken by the students in groups of three. The mutual discussion resulted in a great learning effect and we no longer need to use proctoring.

## Summative

> Since we offer a practice test with proctoring, we experience far fewer technical problems when administering the online tests.

### Preparation

Before you start constructing the exam questions, first draw up a test matrix/specification table to ensure that the various knowledge and skill aspects that the test aims to measure are covered and thus ensure content validity [@van2017toetsen]. For this, see for example [this guide from Hogeschool Utrecht](https://husite.nl/toetsing-nieuw/toetscyclus/constructie/het-opstellen-van-een-toetsmatrijs/).

You preferably compile your exam questions by using a personal or shared item bank, so that you can reuse questions later. More information about this can be found in the [Handboek Itembanken](https://werkgroep-TESting-op-distance.github.io/Handboek-Itembanken/) and in the [SURF theme edition Digital test and question banks in education] (https://www.surf.nl/files/2019-02/thema-uitgave-itembanken_-webversie_def.pdf).

Generally, the more questions that are included in the test, the higher the reliability. For a test with closed questions, it is recommended to include forty (in the case of four-choice questions) to sixty (in the case of three-choice questions) questions, in order to achieve an acceptable reliability [@van2017toetsen].

Apply the four-eyes principle: present the test questions to a colleague and ask for feedback [@van2017toetsen].

To prevent fraud, randomize questions and answer options or give students different test questions. Using item banks makes it easier to create multiple test versions with different sets of questions. More information about this can be found in the [Handbook Item Banks](https://werkgroep-KEYS-op-distance.github.io/Handbook-Itembanken/). Offering questions and answer options in a random order is easy with a digital testing application.

Set an appropriate time limit: too much time increases the risk of fraud, but a lack of time causes stress for students and less valid test results. See van [Berkel (1999)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjKnODgsO_zAhVH7rsIHageBcQQFnoECAUQAQ&url=https%3A%2F%2Fwww.uu.nl%2Fsites%2Fdefault%2Ffiles%2Finschatting_beantwoordingstijd_naar_vraagtype_van_berkel_1999_ot.pdf&usg=AOvVaw0QbDntv3c6E8vkehprB403) for time indications.

Depending on the set-up of the testing process within your institution, some tasks such as planning the test, adding students to the test and informing students are done for you to a greater or lesser extent.

#### In case of remote testing:

Communicate clearly and properly about the use of an online proctoring method. Not all students have a suitable room at home or have the necessary equipment; this can certainly be a problem for tests with proctoring. Indicate at an early stage what you expect from the students, what they need, how they can receive support from the institution (e.g. loan equipment or an alternative test location) and how they can practice prior to the test.

For a test with proctoring, offer a practice test with which the student can practice using the system. This is also important for students who use speech or reading software due to a visual or hearing impairment.

### During

To ensure the reliability of the test, ensure that the conditions under which the test is taken are as equal as possible for all students.

When taking the test, ensure authentication by proof of registration in combination with asking for proof of identification. Make the rules of conduct and the permitted sources and aids known to the students during the test, as well as the method of handling irregularities, including fraud, the way in which results are communicated, and the options for inspection. Also ensure proper surveillance and let the Board of Examiners investigate (particularly for remote tests) whether and, if so, to what extent the inherent limitations of the surveillance pose a threat to the reliability of the measurement. It is recommended to have a report written of the test taking, which mentions incidents deemed relevant, malfunctions, irregularities, alleged attempts at fraud, questions from students for clarification, attempts to enter into discussion with invigilators, frequent toilet visits, massive early departure of students or the massive use of the last seconds. For examiners, this information provides possible starting points for the final standardization and for an evaluation of the quality of the test in question [@van2017toetsen].

Taking knowledge tests digitally is relatively susceptible to fraud. That is why it is necessary to take measures to counter this. Digital testing systems can offer opportunities to prevent fraud as much as possible. For example, an assessment system can switch off certain computer functions so that students are temporarily unable to open external web pages.

#### In case of remote testing:

Online surveillance can be used for remote assessments to prevent fraud. Live monitoring means that a teacher is present in a video conference where students are viewed in real time, for example via a webcam or telephone. With recorded proctoring, video recordings are made that are viewed randomly afterwards. Automated proctoring means that special detection software automatically checks for things that are unusual, such as unexpected movements or ambient sounds. More information about online proctoring can be found [here](https://www.surf.nl/whitepaper-online-proctoring-surveilleren-op-afstand).

### After

Process and analyze the results of the test. Also look at the quality of the items, using psychometric data such as the trip value. If the analysis reveals items of poor quality, take steps to improve them, either for the test already administered (as in the case of an answer key entered incorrectly) or for administration in a future test. See, for example, [this guide from Hogeschool Utrecht for more information about test analysis](https://husite.nl/toetsing-nieuw/toetscyclus/evalueren-en-verbeteren/). If a relative cut-off point or a compromise method [@van2017toetsen] has been chosen, then determine the final cut-off point now on the basis of the test results.

#### In case of remote assessment:

The processing of the proctoring results afterwards does not only depend on the chosen proctoring method, but also on the process agreements that have been made within the institution. So inquire about the policy and the working method.

If 'recorded proctoring' or 'automated proctoring' is used, the recordings must be analysed. Possible cases of fraud are then submitted to the examiner or board of examiners for assessment. If recorded proctoring has been used, do not record the results until no problems have emerged.

The processing of the test results continues in the same way as digital testing on campus.

### Points of attention

* Make a substantiated choice for the cut-off score to be used. For guidelines, see for example [Soeting and Haykens (n.d.)](https://husite.nl/toetsing-nieuw/wp-content/uploads/sites/299/2020/02/Cesuurrichting.pdf)
* Collect and analyze psychometric data from the test and test questions, such as the confidence coefficient and the trip values (usually test applications provide options for this). Use this data to improve the quality of the test (questions).
* Specifically for tests with open questions, it is recommended to engage a second assessor. Let the raters evaluate the answers independently of each other using a pre-constructed correction rule.

#### In case of remote testing:

* Remote tests carry a greater risk of fraud than on-campus tests, especially when closed questions are used. In addition to measures such as online proctoring, you can consider whether you can use as many open questions as possible. Please note that this considerably increases the grading time.
* For students who have serious objections to the use of online proctoring, many institutions offer the option of taking the test on campus.

> In the national training program for clinical perfusionists, digital tests are administered using automated proctoring. Since the introduction, students no longer have to travel from Groningen or Maastricht to Leiden to take a test.